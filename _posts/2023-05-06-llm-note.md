---
layout:       post
title:        "LLM 大模型工作"
subtitle:     " \"时间是金\""
date:         2023-05-06 19:09:00
author:       "王川"
header-img:   "img/bg-Jordan_Solo.jpg"
catalog:      true
tags:
    - LLM
    - NLP
    - Demo
    - 实践
---

# Chuan的Demo

自去年11月OpenAI公布chatGPT以来，大模型持续被推到热度的顶点，我从研究生时期就持续保持对预训练大模型的研究与关注。

终于有一天，pretrain和RL再一次以Emergent Ability的方式涌现到大众眼前，基于A100的加持我也开展了大量的LLM工作。

这里对于LLM工作做简介以及demo做展示。


# LLM工作

1. 175B参数量的基于GPT2的预训练
2. 175B参数量的基于BLOOM的SFT有监督微调
3. 7B参数量的基于BLOOM/BLOOMZ的SFT
4. 6B参数量的chatGLM的SFT
5. 6B参数量的LLAMA的SFT
6. DEMO展示，结合工作中业务落地，形成数据飞轮收集数据
7. 基于DEEPSPEED-CHAT的RLHF（ing：）

# DEMO

因网络与资源敏感等限制，贴视频如下：


